1. Run a spark job to load data into a s3
2. Build and Run a crawler to create table.
3. Run a spark job to load data into a s3 to a load_date folder
4. Build and Run a crawler to create table.  Check the partition.
5. Run the spark job to add another folder.load_date folder
6. Run crawler again to see the new metadata.
7. Add a new col in the datasets by changing the spark code.
8. Run crawler again to see the new metadata.