Build Pyspark job to do this.
1. Read the transaction csv file . (10 files 1 by 1)
2. Add load_time  (current_time)
3. concat first_name and last name along with space in between. The new col is name.
4. get the first two character of account id. if its CK the create a new field account_type as Checking
if its PV then Private and else saving.
5. Drop the account_id_type col from dataset.
6. Load data into a new folder with customer_pyspark and each day add a partition of the day .
 lets say you are running for 2023-01-01 then partition is same